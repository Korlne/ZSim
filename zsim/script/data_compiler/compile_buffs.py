import pandas as pd
import json
import os
import sys
import numpy as np

# ================= é…ç½®åŒºåŸŸ =================
# å®šä½åˆ° zsim åŒ…çš„æ ¹ç›®å½•
# å‡è®¾è„šæœ¬ä½äº zsim/script/data_compiler/
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
ZSIM_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(CURRENT_DIR))) # .../zsim
DATA_DIR = os.path.join(ZSIM_ROOT, 'zsim', 'data')

# æ­¤æ—¶ä¿®æ­£è·¯å¾„é€»è¾‘ï¼šå¦‚æœ CURRENT_DIR æ˜¯ .../zsim/script/data_compiler
# up1 -> script, up2 -> zsim, up3 -> é¡¹ç›®æ ¹ç›®å½•?
# è®©æˆ‘ä»¬ä½¿ç”¨ç›¸å¯¹è·¯å¾„æ›´ç¨³å¥çš„æ–¹å¼ï¼š
# ç›®æ ‡æ˜¯æ‰¾åˆ° zsim/data
# å¦‚æœè„šæœ¬åœ¨ zsim/script/data_compiler/
# os.path.dirname(__file__) -> data_compiler
# .parent -> script
# .parent -> zsim
# .parent -> é¡¹ç›®æ ¹ (å¦‚æœæ˜¯) æˆ– zsim (å¦‚æœæ˜¯åŒ…å†…è¿è¡Œ)

# ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å‘ä¸ŠæŸ¥æ‰¾ç›´åˆ°æ‰¾åˆ° 'data' æ–‡ä»¶å¤¹
def find_data_dir(start_path):
    path = start_path
    for _ in range(4): # æœ€å¤šæ‰¾4å±‚
        if os.path.exists(os.path.join(path, 'data')):
            return os.path.join(path, 'data')
        path = os.path.dirname(path)
    return None

DATA_DIR = find_data_dir(CURRENT_DIR)
if not DATA_DIR:
    # å›é€€ç¡¬ç¼–ç 
    DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(CURRENT_DIR))), 'zsim', 'data')

SOURCE_DIR = os.path.join(DATA_DIR, 'buff_config_source')
OUTPUT_DIR = os.path.join(DATA_DIR, 'generated')
OUTPUT_FILE = os.path.join(OUTPUT_DIR, 'buff_db.json')

# ===========================================

def safe_json_load(json_str):
    """è§£æ CSV ä¸­çš„ JSON å­—ç¬¦ä¸²ï¼Œå¤„ç†ç©ºå€¼å’Œæ ¼å¼é”™è¯¯"""
    if pd.isna(json_str) or str(json_str).strip() == "":
        return None
    try:
        return json.loads(str(json_str))
    except json.JSONDecodeError:
        # å°è¯•ä¿®å¤å¸¸è§çš„å•å¼•å·é”™è¯¯
        try:
            return json.loads(str(json_str).replace("'", '"'))
        except:
            return None

def convert_value(val):
    """æ™ºèƒ½è½¬æ¢æ•°å€¼ç±»å‹"""
    if pd.isna(val):
        return 0
    try:
        f_val = float(val)
        if f_val.is_integer():
            return int(f_val)
        return f_val
    except ValueError:
        return str(val)

def compile_buffs():
    print(f"ğŸš€ [ZSim] å¼€å§‹ç¼–è¯‘ Buff æ•°æ®...")
    print(f"   æºç›®å½•: {SOURCE_DIR}")
    
    if not os.path.exists(SOURCE_DIR):
        print(f"âŒ é”™è¯¯: æºç›®å½•ä¸å­˜åœ¨ã€‚è¯·å…ˆè¿è¡Œ migrate_legacy_csv.py")
        return

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # 1. è¯»å– CSV
    reg_path = os.path.join(SOURCE_DIR, 'buff_registry.csv')
    eff_path = os.path.join(SOURCE_DIR, 'buff_effects.csv')
    
    try:
        # dtype=str ä¿è¯ ID ä¸ä¼šè¢«è¯»æˆæ•°å­—ä»è€Œä¸¢å¤±å‰å¯¼é›¶ï¼ˆå¦‚æœæœ‰ï¼‰
        df_reg = pd.read_csv(reg_path, dtype={'buff_id': str})
        df_eff = pd.read_csv(eff_path, dtype={'buff_id': str})
    except Exception as e:
        print(f"âŒ è¯»å– CSV å¤±è´¥: {e}")
        return

    buff_db = {}
    
    # 2. å¤„ç†åŸºç¡€é…ç½® (Registry)
    print("   æ­£åœ¨æ„å»º Buff å¯¹è±¡æ ‘...")
    for _, row in df_reg.iterrows():
        buff_id = row['buff_id']
        if pd.isna(buff_id): continue

        # å¤„ç† tags
        tags = []
        if not pd.isna(row.get('tags')):
            tags = [t.strip() for t in str(row['tags']).split(',') if t.strip()]

        feature = {
            "buff_id": buff_id,
            "name": str(row.get('buff_name', f"Buff_{buff_id}")),
            "max_stacks": int(row.get('max_stacks', 1)),
            "max_duration": float(row.get('max_duration', -1)),
            "stack_increment": int(row.get('stack_increment', 1)),
            "independent_stacks": str(row.get('independent_stacks')).lower() == 'true',
            "allows_refresh": str(row.get('allows_refresh')).lower() != 'false', # é»˜è®¤ä¸º True
            "tags": tags
        }
        
        buff_db[buff_id] = {
            "feature": feature,
            "effects": []
        }

    # 3. å¤„ç†æ•ˆæœ (Effects)
    print("   æ­£åœ¨æ³¨å…¥ Effects é€»è¾‘...")
    orphan_count = 0
    
    for idx, row in df_eff.iterrows():
        buff_id = row['buff_id']
        if pd.isna(buff_id): continue
        
        if buff_id not in buff_db:
            orphan_count += 1
            continue

        # åŸºç¡€ Effect æ•°æ®
        effect_data = {
            "type": row.get('effect_type', 'bonus'),
        }

        # Bonus ç‰¹æœ‰å­—æ®µ
        if not pd.isna(row.get('target_key')):
            effect_data['target_key'] = str(row['target_key'])
            
        if not pd.isna(row.get('value')):
            effect_data['value'] = convert_value(row['value'])

        # Trigger ç‰¹æœ‰å­—æ®µ
        if not pd.isna(row.get('trigger_event')):
            effect_data['trigger_event'] = str(row['trigger_event'])

        # é€šç”¨ JSON å­—æ®µ
        conditions = safe_json_load(row.get('conditions'))
        if conditions: 
            effect_data['conditions'] = conditions
            
        actions = safe_json_load(row.get('actions'))
        if actions: 
            effect_data['actions'] = actions

        buff_db[buff_id]['effects'].append(effect_data)

    # 4. è¾“å‡º JSON
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(buff_db, f, indent=2, ensure_ascii=False)

    print(f"âœ… ç¼–è¯‘æˆåŠŸ!")
    print(f"   - Buff æ€»æ•°: {len(buff_db)}")
    print(f"   - è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    if orphan_count > 0:
        print(f"   âš ï¸ è·³è¿‡äº† {orphan_count} ä¸ªæ²¡æœ‰å¯¹åº”åŸºç¡€é…ç½®çš„æ•ˆæœæ¡ç›®")

if __name__ == "__main__":
    compile_buffs()